{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit2ae39281a9e44a899ce84a46cd7f36a9",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ERROR ANALYSIS ##\n",
    "import Ch3_2_performance_measures as pm\n",
    "import Ch3_3_multiclass_classification as mc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X_train= mc.X_train\n",
    "y_train = mc.y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(mc.sgd_clf, mc.X_train_scaled, mc.y_train, cv = 3)\n",
    "conf_mx = confusion_matrix(mc.y_train, pm.y_train_pred)\n",
    "print(conf_mx) # shows an array of numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(conf_mx)\n",
    "plt.show() # shows a matrix with shades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To focus the plot on the errors, need to divide each value in the confusion matrix by the number of images\n",
    "# in the corresponding class so that we can compare error rates instead of absolute numbers of errors\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "# Fill the diagonal with zeros to keep only the errors, and plot the result\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "# The rows are the actuals and the columns are the predictions\n",
    "# The chart shows that the column for 8 is bright, meaning may images get misclassified as 8s.\n",
    "# However, the row for 8 looks good, meaning the actual 8s get correctly classified as 8s.\n",
    "# So it looks like the focus should be on reducing false 8s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# There are a number of ways to improve this classifier.\n",
    "# Get more data for digits that looks like 8s,\n",
    "# implement new features to count the number of closed loops,\n",
    "# or preprocess the images to make some patterns, such as closed loops, stand out more.\n",
    "\n",
    "# Analyzing individual errors can also be a good way to gain insights.\n",
    "# For example, let's plot examples of 3s and 5s\n",
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# Run these in Jupyter Notebook\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.show"
   ]
  }
 ]
}