{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbaseconda806df43b87b141bfb712648c9cf8715a",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.80745998,  0.58824429, -0.63512602, -0.15045808, -0.01254803,\n         0.68433502, -0.78520176,  0.66389322],\n       [-0.61417196, -0.60367109,  0.0442543 ,  0.32625567, -0.27737912,\n        -0.3044619 , -0.10253529, -0.65071711],\n       [-0.90910551, -0.60367109, -0.62330614, -0.07523955,  0.22758819,\n        -0.17683045, -0.88339351,  0.63390211],\n       [-1.12912041,  1.14447147, -0.4745537 , -0.15843382, -0.54135866,\n        -0.22014024, -0.74779537,  0.59891248],\n       [-0.38905134, -0.84205417, -0.65185135,  0.28992882, -0.33187812,\n        -0.62565973,  0.45388464, -1.1655645 ],\n       [-0.07343441,  1.06501044, -0.1514906 , -0.04498114,  0.14583969,\n        -0.16878471,  0.91211281, -1.37550228],\n       [-1.2721848 ,  0.98554942, -1.04133655,  0.00550796,  1.27669398,\n         0.47863743, -0.73376798,  0.63890063],\n       [-0.80350044,  0.74716634, -0.25963939,  0.06084503, -0.32080801,\n         0.41344372, -0.71974059,  0.6838873 ],\n       [-0.75317262,  0.11147814, -0.09889313, -0.01272225,  0.39619448,\n         0.47991117, -0.71506479,  0.91381914],\n       [-0.81600425, -0.04744391, -0.63333461, -0.07854482,  1.2426321 ,\n         0.51899915, -0.8880693 ,  1.67359393]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_val_A, X_val_B = X_val[:, :5], X_val[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-95adbf93b5b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# now can use this loss function when compiling a keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mhuber_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nadam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# custom loss function\n",
    "# eg. implementing Huber loss into keras regression model\n",
    "# (can use tf.keras.losses.Huber but pretend it doesn't exist)\n",
    "import tensorflow as tf\n",
    "\n",
    "model = keras.\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1 # bool-type tensor\n",
    "    squared_loss = tf.square(error) / 2 # output1\n",
    "    linearloss = tf.abs(error) - 0.5 # output2\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss) # return output1 if true, output2 if false\n",
    "\n",
    "# now can use this loss function when compiling a keras model\n",
    "model.compile(loss= huber_fn, optimizer=\"nadam\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}